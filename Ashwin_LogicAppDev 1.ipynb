{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import concurrent.futures\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript and Prompt Set Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt import - 41 prompts\n",
    "df_prompts_X = pd.read_csv(r\"C:\\Users\\belie\\OneDrive\\Documents\\GitHub\\AutoQA-FunctionDev\\X\\X Prompts.csv\")\n",
    "\n",
    "# Transcript import\n",
    "def read_files():\n",
    "    # Get all files from 'Call Transcripts_X' folder\n",
    "    files = glob.glob(r'C:\\Users\\belie\\OneDrive\\Documents\\GitHub\\AutoQA-FunctionDev\\X\\Call Transcripts_X/*.txt')\n",
    "    \n",
    "    # Read all filenames and file contents\n",
    "    filenames = []\n",
    "    data = []\n",
    "    \n",
    "    for file in files:\n",
    "        filenames.append(file)  # Store the filename\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data.append(f.read())  # Store the file content\n",
    "    \n",
    "    return filenames, data\n",
    "\n",
    "# Get filenames and transcripts\n",
    "filenames, transcripts = read_files()\n",
    "# Clean filenames to remove .txt extension\n",
    "filenames = [os.path.splitext(os.path.basename(file))[0] for file in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and user prompt setup\n",
    "system_prompt = f\"\"\"\n",
    "Answer questions based on the interaction between a call-center agent and a customer.\n",
    "Ensure the output follows the JSON format below:\n",
    "{{\n",
    "    \"Question #\": \"[Question Number]\",\n",
    "    \"Answer\": \"[Yes/No/NA/Good/Average/Needs Improvement]\"\n",
    "}}\n",
    "Interaction:\n",
    "{transcripts[0]}\n",
    "\"\"\"\n",
    "# \"Justification\": \"[Provide your justification based on the interaction]\"\n",
    "\n",
    "questions = df_prompts_X['Prompt'].tolist()\n",
    "\n",
    "user_prompt = \"\"\n",
    "for i, question in enumerate(questions, 1):\n",
    "    user_prompt += f\"\"\"\n",
    "    Question {i}: {question}\n",
    "    Answer the following in the format provided:\n",
    "    {{\n",
    "        \"Question #\": \"{i}\",\n",
    "        \"Answer\": \"[Yes/No/NA/Good/Average/Needs Improvement]\"\n",
    "    }}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27027"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token Length\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens(text):\n",
    "    encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    tokens = encoder.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "count_tokens(f\"{system_prompt} {user_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication and Payload Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Step 1: Define your variables\n",
    "url = \"https://api.runpod.ai/v2/k9fanpyhc2z8ya/run\"\n",
    "headers = {\"Authorization\": \"Bearer rpa_ARG4EDO1OIMKM70C4J04YBVR1685WN3VB46AFUSU1c54vp\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "payload = {\"input\": {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    \"sampling_params\": {\"temperature\": 0.7, \"max_tokens\": 32768}\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Inference with polling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job submitted. ID: 719b41b8-067e-4d37-8246-eade2b0beee3-u2\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_QUEUE\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: IN_PROGRESS\n",
      "Current status: COMPLETED\n",
      "Job completed.\n",
      "Output: [\n",
      "  {\n",
      "    \"choices\": [\n",
      "      {\n",
      "        \"tokens\": [\n",
      "          \"Okay, I need to evaluate the interaction between the call-center agent and the customer based on the provided transcript. The user has provided a detailed conversation between Marissa and the agent. My task is to answer 41 questions based on specific scoring criteria for each question. I'll go through each question one by one, analyze the conversation, and determine the appropriate answer.\\n\\nStarting with Question 1: The agent did not explicitly mention that the call is being recorded at the beginning. There's no disclosure about the recording until later in the conversation. So the answer would be \\\"No.\\\"\\n\\nQuestion 2: The agent confirmed the account details with Marissa, so the answer is \\\"Yes.\\\"\\n\\nQuestion 3: The agent asked if Marissa is the one responsible for marketing decisions, so \\\"Yes.\\\"\\n\\nQuestion 4: The agent asked about the budget decision maker, so \\\"Yes.\\\"\\n\\nQuestion 5: The agent greeted Marissa and introduced themselves, so \\\"Good.\\\"\\n\\nQuestion 6: The agent mentioned the value of providing tailored solutions, so \\\"Good.\\\"\\n\\nQuestion 7: The agent discussed the purpose and key points, so \\\"Good.\\\"\\n\\nQuestion 8: The agent asked about the business and goals, so \\\"Good.\\\"\\n\\nQuestion 9: The agent asked about marketing goals, so \\\"Good.\\\"\\n\\nQuestion 10: The agent asked about other advertising platforms, so \\\"Good.\\\"\\n\\nQuestion 11: The agent asked about the target audience, so \\\"Good.\\\"\\n\\nQuestion 12: The agent asked about the target location, so \\\"Good.\\\"\\n\\nQuestion 13: The agent asked about KPIs, so \\\"Good.\\\"\\n\\nQuestion 14: The agent asked about conversion tracking, so \\\"Good.\\\"\\n\\nQuestion 15: The agent asked about key dates, so \\\"Good.\\\"\\n\\nQuestion 16: The agent asked about competitors, so \\\"Good.\\\"\\n\\nQuestion 17: The agent asked about creatives, so \\\"Good.\\\"\\n\\nQuestion 18: The agent discussed the budget, so \\\"Good.\\\"\\n\\nQuestion 19: The agent connected the budget to goals, so \\\"Good.\\\"\\n\\nQuestion 20: The agent proposed a budget, so \\\"Good.\\\"\\n\\nQuestion 21: The agent provided tailored solutions, so \\\"Good.\\\"\\n\\nQuestion 22: The agent gave industry-specific advice, so \\\"Good.\\\"\\n\\nQuestion 23: The agent demonstrated product knowledge, so \\\"Good.\\\"\\n\\nQuestion 24: The agent addressed technical issues, so \\\"Good.\\\"\\n\\nQuestion 25: The agent offered a live implementation, so \\\"Good.\\\"\\n\\nQuestion 26: The agent set a follow-up, so \\\"Good.\\\"\\n\\nQuestion 27: The agent handled objections, so \\\"Good.\\\"\\n\\nQuestion 28: The agent maintained call control, so \\\"Good.\\\"\\n\\nQuestion 29: The agent personalized the interaction, so \\\"Good.\\\"\\n\\nQuestion 30: The agent actively listened, so \\\"Good.\\\"\\n\\nQuestion 31: The agent was professional, so \\\"Good.\\\"\\n\\nQuestion 32: The agent summarized key points, so \\\"Good.\\\"\\n\\nQuestion 33: The agent summarized changes, so \\\"Good.\\\"\\n\\nQuestion 34: The agent set next steps, so \\\"Good.\\\"\\n\\nQuestion 35: The agent scheduled a follow-up, so \\\"Good.\\\"\\n\\nQuestion 36: The agent didn't make any changes, so \\\"No.\\\"\\n\\nQuestion 37: No guarantees were made, so \\\"No.\\\"\\n\\nQuestion 38: No bribery discussed, so \\\"No.\\\"\\n\\nQuestion 39: No rude behavior, so \\\"No.\\\"\\n\\nQuestion 40: No confidential info shared, so \\\"No.\\\"\\n\\nQuestion 41: No background noise, so \\\"No.\\\"\\n</think>\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"1\\\",\\n    \\\"Answer\\\": \\\"No\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"2\\\",\\n    \\\"Answer\\\": \\\"Yes\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"3\\\",\\n    \\\"Answer\\\": \\\"Yes\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"4\\\",\\n    \\\"Answer\\\": \\\"Yes\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"5\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"6\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"7\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"8\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"9\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"10\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"11\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"12\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"13\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"14\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"15\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"16\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"17\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"18\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"19\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"20\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"21\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"22\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"23\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"24\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"25\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"26\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"27\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"28\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"29\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"30\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"31\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"32\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"33\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"34\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"35\\\",\\n    \\\"Answer\\\": \\\"Good\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"36\\\",\\n    \\\"Answer\\\": \\\"No\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"37\\\",\\n    \\\"Answer\\\": \\\"No\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"38\\\",\\n    \\\"Answer\\\": \\\"No\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"39\\\",\\n    \\\"Answer\\\": \\\"No\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"40\\\",\\n    \\\"Answer\\\": \\\"No\\\"\\n}\\n```\\n\\n```json\\n{\\n    \\\"Question #\\\": \\\"41\\\",\\n    \\\"Answer\\\": \\\"No\\\"\\n}\\n```\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "      \"input\": 27033,\n",
      "      \"output\": 1671\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Send the job request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to submit job:\", response.text)\n",
    "    exit()\n",
    "\n",
    "response_json = response.json()\n",
    "job_id = response_json[\"id\"]\n",
    "print(f\"Job submitted. ID: {job_id}\")\n",
    "\n",
    "# Step 3: Poll the status endpoint\n",
    "status_url = f\"https://api.runpod.ai/v2/k9fanpyhc2z8ya/status/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    status_response = requests.get(status_url, headers=headers)\n",
    "    status_data = status_response.json()\n",
    "\n",
    "    print(\"Current status:\", status_data[\"status\"])\n",
    "\n",
    "    if status_data[\"status\"] == \"COMPLETED\":\n",
    "        print(\"Job completed.\")\n",
    "        print(\"Output:\", json.dumps(status_data[\"output\"], indent=2))\n",
    "        break\n",
    "    elif status_data[\"status\"] == \"FAILED\":\n",
    "        print(\"Job failed.\")\n",
    "        print(\"Details:\", status_data)\n",
    "        break\n",
    "    elif status_data[\"status\"] == \"CANCELLED\":\n",
    "        print(\"Job cancelled.\")\n",
    "        print(\"Details:\", status_data)\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(1)  # Wait 1 seconds before polling again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Iterative Inferencing - one request sent at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively send requests\n",
    "job_ids = []\n",
    "number_of_requests = 1000\n",
    "\n",
    "for i in range(0, number_of_requests):\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to submit job:\", response.text)\n",
    "        exit()\n",
    "    response_json = response.json()\n",
    "    job_id = response_json[\"id\"]\n",
    "    job_ids.append(job_id)\n",
    "    print(f\"Job submitted. ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Inferencing - 1000 Requests at a time with 2.5 minutes of sleep in between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "\n",
    "TOTAL_REQUESTS = 1000 # adjust based on load of single inference\n",
    "MAX_WORKERS = 200 \n",
    "\n",
    "job_ids = []\n",
    "\n",
    "def send_request(i, max_retries=5):\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()[\"id\"]\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"[{i}] 429 Too Many Requests — backing off for 60s (attempt {attempt+1})\")\n",
    "                time.sleep(60)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                print(f\"[{i}] Failed: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] Exception: {e}\")\n",
    "            time.sleep(5)\n",
    "            attempt += 1\n",
    "    print(f\"[{i}] Failed after {max_retries} retries.\")\n",
    "    return None\n",
    "\n",
    "def send_requests():\n",
    "    start_time = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(send_request, i): i for i in range(TOTAL_REQUESTS)}\n",
    "        for future in as_completed(futures):\n",
    "            job_id = future.result()\n",
    "            if job_id:\n",
    "                job_ids.append(job_id)\n",
    "            if len(job_ids) % 100 == 0:\n",
    "                print(f\"{len(job_ids)} jobs submitted...\")\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n✅  Submitted {len(job_ids)} jobs in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Requests Sent Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 10 \n",
    "# Sending 'factor' batches of 1000 requests to avoid overwhelming the server\n",
    "for i in range(0, factor):\n",
    "    print(f\"Starting batch {i+1} of {1000} requests...\")\n",
    "    send_requests()\n",
    "    print(f\"Sleeping for 150 seconds before next batch...\")\n",
    "    time.sleep(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic App Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Single Job Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tiktoken\n",
    "import logging\n",
    "\n",
    "def validate_inputs(transcript, questions):\n",
    "    if not transcript or not isinstance(transcript, str):\n",
    "        raise ValueError(\"Invalid transcript: Must be a non-empty string.\")\n",
    "    if not questions or not isinstance(questions, list) or not all(isinstance(q, str) for q in questions):\n",
    "        raise ValueError(\"Invalid questions: Must be a list of strings.\")\n",
    "    logging.info(\"Input validation passed.\")\n",
    "\n",
    "def create_prompts(transcript, questions):\n",
    "    logging.info(\"Creating system and user prompts...\")\n",
    "    system_prompt = f\"\"\"\n",
    "    Answer questions based on the interaction between a call-center agent and a customer.\n",
    "    Ensure the output follows the JSON format below:\n",
    "    {{\n",
    "        \"Question #\": \"[Question Number]\",\n",
    "        \"Answer\": \"[Yes/No/NA/Good/Average/Needs Improvement]\"\n",
    "    }}\n",
    "    Interaction:\n",
    "    {transcript}\n",
    "    \"\"\"\n",
    "    user_prompt = \"\"\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        user_prompt += f\"\"\"\n",
    "        Question {i}: {question}\n",
    "        Answer the following in the format provided:\n",
    "        {{\n",
    "            \"Question #\": \"{i}\",\n",
    "            \"Answer\": \"[Yes/No/NA/Good/Average/Needs Improvement]\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "    return system_prompt.strip(), user_prompt.strip()\n",
    "\n",
    "def determine_max_tokens(system_prompt, user_prompt):\n",
    "    ALLOWED_TOKEN_LENGTHS = [1024, 2048, 4096, 8192, 16384, 32768, 65536]\n",
    "    logging.info(\"Encoding prompt for token length...\")\n",
    "    try:\n",
    "        tokens = tiktoken.encoding_for_model(\"gpt-4\").encode(f\"{system_prompt} {user_prompt}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Token encoding failed: {str(e)}\")\n",
    "\n",
    "    token_length = len(tokens)\n",
    "    logging.info(f\"Total token length: {token_length}\")\n",
    "    if token_length > ALLOWED_TOKEN_LENGTHS[-1]:\n",
    "        raise ValueError(f\"Token limit exceeded. Token Length: {token_length}. Max allowed: {ALLOWED_TOKEN_LENGTHS[-1]}\")\n",
    "    \n",
    "    for allowed in ALLOWED_TOKEN_LENGTHS:\n",
    "        if token_length <= allowed:\n",
    "            logging.info(f\"Using max_tokens = {allowed}\")\n",
    "            return allowed\n",
    "    return ALLOWED_TOKEN_LENGTHS[-1]\n",
    "\n",
    "def build_payload(system_prompt, user_prompt, max_tokens):\n",
    "    logging.info(\"Building request payload...\")\n",
    "    return {\n",
    "        \"input\": {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"sampling_params\": {\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_tokens\": max_tokens\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def send_post_request(payload):\n",
    "    RUNPOD_URL = \"https://api.runpod.ai/v2/k9fanpyhc2z8ya/run\"\n",
    "    AUTH_TOKEN = \"Bearer rpa_ARG4EDO1OIMKM70C4J04YBVR1685WN3VB46AFUSU1c54vp\"\n",
    "    headers = {\n",
    "        \"Authorization\": AUTH_TOKEN,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    logging.info(\"Sending POST request to RunPod API...\")\n",
    "    try:\n",
    "        response = requests.post(RUNPOD_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RuntimeError(f\"Job submission failed: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Unexpected error during response handling: {str(e)}\")\n",
    "\n",
    "def extract_job_id(response_json):\n",
    "    job_id = response_json.get(\"id\")\n",
    "    if not job_id:\n",
    "        raise ValueError(f\"Job submission failed: Missing job ID in response: {response_json}\")\n",
    "    return job_id\n",
    "\n",
    "# Main function\n",
    "def submit_job(transcript, questions):\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"job_submission.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        validate_inputs(transcript, questions)\n",
    "        system_prompt, user_prompt = create_prompts(transcript, questions)\n",
    "        max_tokens = determine_max_tokens(system_prompt, user_prompt)\n",
    "        payload = build_payload(system_prompt, user_prompt, max_tokens)\n",
    "        response_json = send_post_request(payload)\n",
    "        job_id = extract_job_id(response_json)\n",
    "        logging.info(f\"Job submitted successfully. ID: {job_id}\")\n",
    "        return job_id\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in submit_job: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-30 15:16:15,025] INFO - Input validation passed.\n",
      "[2025-04-30 15:16:15,025] INFO - Creating system and user prompts...\n",
      "[2025-04-30 15:16:15,027] INFO - Encoding prompt for token length...\n",
      "[2025-04-30 15:16:15,047] INFO - Total token length: 27028\n",
      "[2025-04-30 15:16:15,048] INFO - Using max_tokens = 32768\n",
      "[2025-04-30 15:16:15,049] INFO - Building request payload...\n",
      "[2025-04-30 15:16:15,050] INFO - Sending POST request to RunPod API...\n",
      "[2025-04-30 15:16:15,333] INFO - Job submitted successfully. ID: d674f41a-2468-4988-8565-9a97dcd0fec4-u2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d674f41a-2468-4988-8565-9a97dcd0fec4-u2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_job(transcripts[0], questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Status Polling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import logging\n",
    "\n",
    "def validate_job_id(job_id):\n",
    "    if not job_id or not isinstance(job_id, str):\n",
    "        raise ValueError(\"Invalid job_id: Must be a non-empty string.\")\n",
    "\n",
    "def build_status_url(job_id):\n",
    "    return f\"https://api.runpod.ai/v2/k9fanpyhc2z8ya/status/{job_id}\"\n",
    "\n",
    "def get_job_status(status_url, headers):\n",
    "    try:\n",
    "        response = requests.get(status_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RuntimeError(f\"Status check failed: {str(e)}\")\n",
    "    except ValueError as e:\n",
    "        raise RuntimeError(f\"Invalid JSON in response: {str(e)}\")\n",
    "\n",
    "def process_status_response(status_data):\n",
    "    status = status_data.get(\"status\")\n",
    "    if not status:\n",
    "        raise ValueError(\"Missing 'status' field in response.\")\n",
    "    logging.info(f\"Current status: {status}\")\n",
    "\n",
    "    if status == \"COMPLETED\":\n",
    "        logging.info(\"Job completed.\")\n",
    "        return \"COMPLETED\"\n",
    "    elif status == \"FAILED\":\n",
    "        logging.error(f\"Job failed. Details: {status_data}\")\n",
    "        return \"FAILED\"\n",
    "    elif status == \"CANCELLED\":\n",
    "        logging.warning(f\"Job cancelled. Details: {status_data}\")\n",
    "        return \"CANCELLED\"\n",
    "    return None  # Job still in progress\n",
    "\n",
    "# Main polling function\n",
    "def status_poll(job_id):\n",
    "    AUTH_TOKEN = \"Bearer rpa_ARG4EDO1OIMKM70C4J04YBVR1685WN3VB46AFUSU1c54vp\"\n",
    "    POLL_INTERVAL_SECONDS = 60\n",
    "    # Setup logging (reuse if already configured elsewhere)\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"job_submission.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        validate_job_id(job_id)\n",
    "        status_url = build_status_url(job_id)\n",
    "        headers = {\n",
    "            \"Authorization\": AUTH_TOKEN,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        logging.info(f\"Polling status for job ID: {job_id}\")\n",
    "        while True:\n",
    "            status_data = get_job_status(status_url, headers)\n",
    "            final_status = process_status_response(status_data)\n",
    "            if final_status:\n",
    "                return final_status\n",
    "            logging.info(f\"Job still in progress or in queue. Sleeping for {POLL_INTERVAL_SECONDS} seconds...\")\n",
    "            time.sleep(POLL_INTERVAL_SECONDS)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in status_poll: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-30 15:17:08,274] INFO - Polling status for job ID: d674f41a-2468-4988-8565-9a97dcd0fec4-u2\n",
      "[2025-04-30 15:17:08,418] INFO - Current status: IN_PROGRESS\n",
      "[2025-04-30 15:17:08,419] INFO - Job still in progress or in queue. Sleeping for 60 seconds...\n",
      "[2025-04-30 15:18:08,596] INFO - Current status: COMPLETED\n",
      "[2025-04-30 15:18:08,597] INFO - Job completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETED'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_poll('d674f41a-2468-4988-8565-9a97dcd0fec4-u2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Response Acquisition and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# Helper Functions\n",
    "def extract_json_from_response(raw_response):\n",
    "    try:\n",
    "        def extract_think_content(response_text):\n",
    "            think_match = re.search(r'<think>(.*?)</think>', response_text, re.DOTALL)\n",
    "            think_content = think_match.group(1).strip() if think_match else \"No structured thought content available.\"\n",
    "            remaining_text = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL).strip()\n",
    "            return think_content, remaining_text\n",
    "\n",
    "        def clean_and_dict(text):\n",
    "            cleaned_text = re.sub(r'(?s).*?({.*?})\\s*```$', r'\\1', text).strip()\n",
    "            return ast.literal_eval(cleaned_text)\n",
    "\n",
    "        think_content, final_ans = extract_think_content(raw_response)\n",
    "        logging.info(f\"Extracted final answer segment: {final_ans}\")\n",
    "        cleaned_str = re.sub(r'^[^\\{]*\\{', '{', final_ans, count=1)\n",
    "        logging.info(f\"Cleaned JSON string: {cleaned_str}\")\n",
    "        return clean_and_dict(cleaned_str)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to extract single JSON from response: {str(e)}\")\n",
    "        return f\"Error extracting JSON: {str(e)}\"\n",
    "\n",
    "def extract_jsons_from_response(raw_response):\n",
    "    try:\n",
    "        def extract_think_content(response_text):\n",
    "            think_match = re.search(r'<think>(.*?)</think>', response_text, re.DOTALL)\n",
    "            think_content = think_match.group(1).strip() if think_match else \"No structured thought content available.\"\n",
    "            remaining_text = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL).strip()\n",
    "            return think_content, remaining_text\n",
    "\n",
    "        def clean_and_dict(text):\n",
    "            cleaned_text = re.sub(r'^[^\\{]*\\{', '{', text, count=1)\n",
    "            return ast.literal_eval(cleaned_text)\n",
    "\n",
    "        think_content, final_ans = extract_think_content(raw_response)\n",
    "        json_pattern = r'\\{.*?\\}'\n",
    "        json_matches = re.findall(json_pattern, final_ans, flags=re.DOTALL)\n",
    "\n",
    "        json_dicts = []\n",
    "        for json_str in json_matches:\n",
    "            try:\n",
    "                cleaned_str = re.sub(r'^[^\\{]*\\{', '{', json_str, count=1)\n",
    "                json_dict = clean_and_dict(cleaned_str)\n",
    "                json_dicts.append(json_dict)\n",
    "            except Exception as inner_e:\n",
    "                logging.warning(f\"Failed to parse a JSON block: {str(inner_e)}\")\n",
    "\n",
    "        logging.info(f\"Extracted {len(json_dicts)} JSON blocks from response.\")\n",
    "        return json_dicts\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to extract multiple JSONs from response: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def check_job_status(job_id):\n",
    "    endpoint_id = \"k9fanpyhc2z8ya\"\n",
    "    try:\n",
    "        url = f\"https://api.runpod.ai/v2/{endpoint_id}/status/{job_id}\"\n",
    "        headers = {\"Authorization\": f\"Bearer rpa_ARG4EDO1OIMKM70C4J04YBVR1685WN3VB46AFUSU1c54vp\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching job status for {job_id}: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def validate_resp(job_id, num_of_questions):\n",
    "    # Logging setup (reuse existing config if already defined)\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[%(asctime)s] %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"job_submission.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        status = check_job_status(job_id)\n",
    "        output = status.get('output')\n",
    "        if not output:\n",
    "            raise ValueError(\"No output field found in job response.\")\n",
    "\n",
    "        response_text = output[0].get('choices', [{}])[0].get('tokens', [None])[0]\n",
    "        if not response_text:\n",
    "            raise ValueError(\"Missing response tokens from job output.\")\n",
    "\n",
    "        jsons = extract_jsons_from_response(response_text)\n",
    "        if len(jsons) == num_of_questions:\n",
    "            logging.info(f\"Job {job_id} returned a valid response with {len(jsons)} items.\")\n",
    "            return jsons\n",
    "        else:\n",
    "            logging.warning(f\"Job {job_id} returned {len(jsons)} items, expected {num_of_questions}.\")\n",
    "            return f\"Job {job_id} returned an invalid response.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error validating response for job {job_id}: {str(e)}\")\n",
    "        return f\"Error validating response: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-30 15:18:54,897] INFO - Extracted 41 JSON blocks from response.\n",
      "[2025-04-30 15:18:54,897] INFO - Job d674f41a-2468-4988-8565-9a97dcd0fec4-u2 returned a valid response with 41 items.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Question #': '1', 'Answer': 'Yes'},\n",
       " {'Question #': '2', 'Answer': 'Yes'},\n",
       " {'Question #': '3', 'Answer': 'Yes'},\n",
       " {'Question #': '4', 'Answer': 'Yes'},\n",
       " {'Question #': '5', 'Answer': 'Good'},\n",
       " {'Question #': '6', 'Answer': 'Yes'},\n",
       " {'Question #': '7', 'Answer': 'Yes'},\n",
       " {'Question #': '8', 'Answer': 'Yes'},\n",
       " {'Question #': '9', 'Answer': 'No'},\n",
       " {'Question #': '10', 'Answer': 'Yes'},\n",
       " {'Question #': '11', 'Answer': 'No'},\n",
       " {'Question #': '12', 'Answer': 'Yes'},\n",
       " {'Question #': '13', 'Answer': 'Yes'},\n",
       " {'Question #': '14', 'Answer': 'Yes'},\n",
       " {'Question #': '15', 'Answer': 'No'},\n",
       " {'Question #': '16', 'Answer': 'No'},\n",
       " {'Question #': '17', 'Answer': 'Yes'},\n",
       " {'Question #': '18', 'Answer': 'Yes'},\n",
       " {'Question #': '19', 'Answer': 'Good'},\n",
       " {'Question #': '20', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '21', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '22', 'Answer': 'No'},\n",
       " {'Question #': '23', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '24', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '25', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '26', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '27', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '28', 'Answer': 'Average'},\n",
       " {'Question #': '29', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '30', 'Answer': 'Yes'},\n",
       " {'Question #': '31', 'Answer': 'Good'},\n",
       " {'Question #': '32', 'Answer': 'Yes'},\n",
       " {'Question #': '33', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '34', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '35', 'Answer': 'Needs Improvement'},\n",
       " {'Question #': '36', 'Answer': 'Yes'},\n",
       " {'Question #': '37', 'Answer': 'No'},\n",
       " {'Question #': '38', 'Answer': 'No'},\n",
       " {'Question #': '39', 'Answer': 'Yes'},\n",
       " {'Question #': '40', 'Answer': 'No'},\n",
       " {'Question #': '41', 'Answer': 'Yes'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_resp('d674f41a-2468-4988-8565-9a97dcd0fec4-u2', len(questions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
